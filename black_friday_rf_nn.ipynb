{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "black_friday_rf_nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUkxY0o8i8RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing libraries for data loading and data preparation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewmx0bNHjVeE",
        "colab_type": "code",
        "outputId": "10370169-93ab-416f-f12c-9d173258aaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#read necessary files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKab3vS4kZq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/black_friday')\n",
        "train = pd.read_csv('BlackFriday_train.csv')\n",
        "test = pd.read_csv('BlackFriday_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wICN3LKDmCyp",
        "colab_type": "code",
        "outputId": "bf0c1111-b7bc-4e8a-f3eb-7b40e3b6c719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#combining both test and train data to do processing together\n",
        "train['Type'] = 1\n",
        "test['Type'] = 0\n",
        "fullData = pd.concat([train, test], axis = 0)\n",
        "print(fullData.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Age', 'City_Category', 'Gender', 'Marital_Status', 'Occupation',\n",
            "       'Product_Category_1', 'Product_Category_2', 'Product_Category_3',\n",
            "       'Product_ID', 'Purchase', 'Stay_In_Current_City_Years', 'Type',\n",
            "       'User_ID'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yubVwQ2Pmgzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#identifying continuous and categorical value columns\n",
        "ID_col = ['User_ID','Product_ID']\n",
        "flag_col = ['Type']\n",
        "target_col = ['Purchase']\n",
        "cat_cols = ['Age', 'City_Category', 'Gender', 'Marital_Status', 'Occupation',\n",
        "       'Product_Category_1', 'Product_Category_2', 'Product_Category_3',\n",
        "       'Stay_In_Current_City_Years']\n",
        "num_cols= list(set(list(fullData.columns))-set(cat_cols)-set(ID_col)-set(target_col)-set(flag_col))\n",
        "\n",
        "#combined numerical and categorical variables\n",
        "num_cat_cols = num_cols + cat_cols\n",
        "\n",
        "#create a new variable for each variable having missing value with VariableNmae_NA\n",
        "#flag mission value with 1 and the other with 0\n",
        "\n",
        "for var in num_cat_cols:\n",
        "  if fullData[var].isnull().any() == True:\n",
        "    fullData[var + '_NA'] = fullData[var].isnull()*1\n",
        "    \n",
        "\n",
        "#impute numerical missing value with mean\n",
        "fullData[num_cols] = fullData[num_cols].fillna(fullData[num_cols].mean())\n",
        "\n",
        "#impute categorical missing value with -9999\n",
        "fullData[cat_cols] = fullData[cat_cols].fillna(value = -9999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoNKhAne3SJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating label encoders for categorical variables\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for var in cat_cols:\n",
        "  number = LabelEncoder()\n",
        "  fullData[var] = number.fit_transform(fullData[var].astype('str'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVUj9dem3d-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalizing the data\n",
        "features = list(set(list(fullData.columns))-set(ID_col)-set(target_col))\n",
        "fullData[features] = fullData[features]/fullData[features].max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZgFwIWqEv-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create validation set for the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = fullData[fullData['Type'] == 1]\n",
        "test = fullData[fullData['Type'] == 0]\n",
        "features = list(set(list(fullData.columns)) - set(ID_col) - set(target_col) - set(flag_col))\n",
        "\n",
        "X = train[features].values\n",
        "y = train[target_col].values\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.30, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzy8JtvDHChD",
        "colab_type": "code",
        "outputId": "ac5056c8-f117-4912-876f-4d54db378bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import random\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "random.seed(42)\n",
        "rf = RandomForestRegressor(n_estimators = 10)\n",
        "rf.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                      n_jobs=None, oob_score=False, random_state=None,\n",
              "                      verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-qHucLF1mOh",
        "colab_type": "code",
        "outputId": "cc01c9fd-0532-4716-a13f-a0fcf1971d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy2fJEcIIDZs",
        "colab_type": "code",
        "outputId": "eb08af58-d73d-4855-8399-8ac600d524e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#regression model using NN(keras)\n",
        "#define model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim = 11, activation = 'relu'))\n",
        "model.add(Dense(50, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "#compile model\n",
        "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mean_squared_error'])\n",
        "\n",
        "#fit model\n",
        "model.fit(X_train, y_train, epochs = 10, validation_data = (X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 100)               1200      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 6,301\n",
            "Trainable params: 6,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 338673 samples, validate on 145146 samples\n",
            "Epoch 1/10\n",
            "338673/338673 [==============================] - 15s 46us/step - loss: 24842471.4099 - mean_squared_error: 24842471.4099 - val_loss: 19608183.9983 - val_mean_squared_error: 19608183.9983\n",
            "Epoch 2/10\n",
            "338673/338673 [==============================] - 15s 45us/step - loss: 19303959.4271 - mean_squared_error: 19303959.4271 - val_loss: 18884822.8569 - val_mean_squared_error: 18884822.8569\n",
            "Epoch 3/10\n",
            "338673/338673 [==============================] - 15s 45us/step - loss: 18843431.8408 - mean_squared_error: 18843431.8408 - val_loss: 18589869.4858 - val_mean_squared_error: 18589869.4858\n",
            "Epoch 4/10\n",
            "338673/338673 [==============================] - 15s 45us/step - loss: 18547822.2188 - mean_squared_error: 18547822.2188 - val_loss: 18262282.7833 - val_mean_squared_error: 18262282.7833\n",
            "Epoch 5/10\n",
            "338673/338673 [==============================] - 15s 45us/step - loss: 18219747.8292 - mean_squared_error: 18219747.8292 - val_loss: 17947610.6047 - val_mean_squared_error: 17947610.6047\n",
            "Epoch 6/10\n",
            "338673/338673 [==============================] - 16s 46us/step - loss: 17902454.6757 - mean_squared_error: 17902454.6757 - val_loss: 17652041.7914 - val_mean_squared_error: 17652041.7914\n",
            "Epoch 7/10\n",
            "338673/338673 [==============================] - 15s 46us/step - loss: 17651244.2571 - mean_squared_error: 17651244.2571 - val_loss: 17492595.3031 - val_mean_squared_error: 17492595.3031\n",
            "Epoch 8/10\n",
            "338673/338673 [==============================] - 15s 45us/step - loss: 17536666.6970 - mean_squared_error: 17536666.6970 - val_loss: 17442187.5687 - val_mean_squared_error: 17442187.5687\n",
            "Epoch 9/10\n",
            "338673/338673 [==============================] - 15s 45us/step - loss: 17494640.0668 - mean_squared_error: 17494640.0668 - val_loss: 17406424.2944 - val_mean_squared_error: 17406424.2944\n",
            "Epoch 10/10\n",
            "338673/338673 [==============================] - 15s 45us/step - loss: 17482200.4740 - mean_squared_error: 17482200.4740 - val_loss: 17389950.1308 - val_mean_squared_error: 17389950.1308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4f22855fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99s4X4es32RP",
        "colab_type": "code",
        "outputId": "aa73953e-75ab-4b44-9d16-d3b8d3a16c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "#evaluation\n",
        "#evaluation from random forest\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "pred = rf.predict(X_valid)\n",
        "score = np.sqrt(mean_squared_error(y_valid, pred))\n",
        "print(score)\n",
        "\n",
        "pred = model.predict(X_valid)\n",
        "score = np.sqrt(mean_squared_error(y_valid, pred))\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3127.6047101559607\n",
            "4170.125913933396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip7wC6tC5tC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#select the independent variables for the test data\n",
        "X_test = test[features].values\n",
        "\n",
        "#prediction from random forest\n",
        "y_test_rf = rf.predict(X_test)\n",
        "\n",
        "#prediction from nn\n",
        "y_test_nn = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW8Z84Yx6mCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}